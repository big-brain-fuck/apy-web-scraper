2025-02-27 01:06:33,714 [INFO] Scrapy 2.11.1 started (bot: kp)
2025-02-27 01:06:33,718 [INFO] Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 01:07:21,174 [INFO] Scrapy 2.11.1 started (bot: kp)
2025-02-27 01:07:21,186 [INFO] Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 01:07:21,189 [INFO] Enabled addons:
[]
2025-02-27 01:07:21,191 [DEBUG] Using selector: EpollSelector
2025-02-27 01:07:21,192 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 01:07:21,192 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 01:07:21,221 [INFO] Telnet Password: 8e0eb00e604176c7
2025-02-27 01:07:21,314 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 01:07:21,315 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 01:07:21,349 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:07:21,351 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:07:21,470 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:07:21,470 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:07:21,478 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:07:21,479 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:08:19,800 [INFO] Scrapy 2.11.1 started (bot: kp)
2025-02-27 01:08:19,802 [INFO] Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 01:08:19,804 [INFO] Enabled addons:
[]
2025-02-27 01:08:19,804 [DEBUG] Using selector: EpollSelector
2025-02-27 01:08:19,805 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 01:08:19,805 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 01:08:19,823 [INFO] Telnet Password: 0424fb40e09b0aca
2025-02-27 01:08:19,869 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 01:08:19,870 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 01:08:19,886 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:08:19,887 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:08:19,928 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:08:19,929 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:08:19,932 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:08:19,933 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:09:45,580 [INFO] Scrapy 2.11.1 started (bot: kp)
2025-02-27 01:09:45,583 [INFO] Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 01:09:45,584 [INFO] Enabled addons:
[]
2025-02-27 01:09:45,585 [DEBUG] Using selector: EpollSelector
2025-02-27 01:09:45,586 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 01:09:45,586 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 01:09:45,602 [INFO] Telnet Password: c4d242f2a819b150
2025-02-27 01:09:45,646 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 01:09:45,646 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 01:09:45,660 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:09:45,669 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:09:45,739 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:09:45,739 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:09:45,741 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:09:45,743 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:10:23,839 [INFO] Scrapy 2.11.1 started (bot: kp)
2025-02-27 01:10:23,841 [INFO] Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 01:10:23,844 [INFO] Enabled addons:
[]
2025-02-27 01:10:23,846 [DEBUG] Using selector: EpollSelector
2025-02-27 01:10:23,847 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 01:10:23,847 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 01:10:23,865 [INFO] Telnet Password: d96158cfc18633e9
2025-02-27 01:10:23,911 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 01:10:23,912 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 01:10:23,932 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:10:23,934 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:10:23,985 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:10:23,985 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:10:23,988 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:10:23,991 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:12:12,339 [INFO] Scrapy 2.11.1 started (bot: kp)
2025-02-27 01:12:12,341 [INFO] Versions: lxml 5.2.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.0.13 30 Jan 2024), cryptography 41.0.7, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 01:12:12,343 [INFO] Enabled addons:
[]
2025-02-27 01:12:12,343 [DEBUG] Using selector: EpollSelector
2025-02-27 01:12:12,343 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 01:12:12,344 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 01:12:12,357 [INFO] Telnet Password: 40f07634eec40452
2025-02-27 01:12:12,409 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 01:12:12,410 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 01:12:12,430 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:12:12,432 [ERROR] Loading "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/handlers/__init__.py", line 55, in _load_handler
    dhcls = load_object(path)
            ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:12:12,477 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:12:12,477 [CRITICAL] Unhandled error in Deferred:
2025-02-27 01:12:12,481 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 01:12:12,482 [CRITICAL] 
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/twisted/internet/defer.py", line 2003, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/lib/python3/dist-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/lib/python3/dist-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/lib/python3/dist-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/lib/python3/dist-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright'
2025-02-27 13:41:47,775 [INFO] Scrapy 2.12.0 started (bot: kp)
2025-02-27 13:41:47,780 [INFO] Versions: lxml 5.3.1.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 13:41:47,784 [INFO] Enabled addons:
[]
2025-02-27 13:41:47,785 [WARNING] /root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-02-27 13:41:47,787 [DEBUG] Using selector: EpollSelector
2025-02-27 13:41:47,788 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 13:41:47,789 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 13:41:47,789 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 13:41:47,789 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 13:41:47,801 [INFO] Telnet Password: 90d787c1b6274e75
2025-02-27 13:41:47,887 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 13:41:47,888 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 13:41:48,453 [CRITICAL] Unhandled error in Deferred:
2025-02-27 13:41:48,453 [CRITICAL] Unhandled error in Deferred:
2025-02-27 13:41:48,455 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-27 13:41:48,456 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-27 13:43:29,656 [INFO] Scrapy 2.12.0 started (bot: kp)
2025-02-27 13:43:29,659 [INFO] Versions: lxml 5.3.1.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 13:43:29,662 [INFO] Enabled addons:
[]
2025-02-27 13:43:29,663 [WARNING] /root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-02-27 13:43:29,664 [DEBUG] Using selector: EpollSelector
2025-02-27 13:43:29,664 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 13:43:29,664 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 13:43:29,664 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 13:43:29,664 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 13:43:29,667 [INFO] Telnet Password: f8185b24a77a0a27
2025-02-27 13:43:29,692 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 13:43:29,693 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 13:43:29,844 [CRITICAL] Unhandled error in Deferred:
2025-02-27 13:43:29,844 [CRITICAL] Unhandled error in Deferred:
2025-02-27 13:43:29,848 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-27 13:43:29,850 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-27 14:13:17,741 [INFO] Scrapy 2.12.0 started (bot: kp)
2025-02-27 14:13:17,754 [INFO] Versions: lxml 5.3.1.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-27 14:13:17,761 [INFO] Enabled addons:
[]
2025-02-27 14:13:17,765 [WARNING] /root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-02-27 14:13:17,768 [DEBUG] Using selector: EpollSelector
2025-02-27 14:13:17,771 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 14:13:17,771 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 14:13:17,771 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-27 14:13:17,771 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-27 14:13:17,785 [INFO] Telnet Password: 5acb4e5fef9bf72d
2025-02-27 14:13:17,891 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-27 14:13:17,892 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-27 14:13:18,410 [CRITICAL] Unhandled error in Deferred:
2025-02-27 14:13:18,411 [CRITICAL] Unhandled error in Deferred:
2025-02-27 14:13:18,438 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-27 14:13:18,443 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-28 16:11:26,639 [INFO] Scrapy 2.12.0 started (bot: kp)
2025-02-28 16:11:26,643 [INFO] Versions: lxml 5.3.1.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
2025-02-28 16:11:26,645 [INFO] Enabled addons:
[]
2025-02-28 16:11:26,646 [WARNING] /root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-02-28 16:11:26,647 [DEBUG] Using selector: EpollSelector
2025-02-28 16:11:26,647 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-28 16:11:26,647 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-28 16:11:26,647 [DEBUG] Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-02-28 16:11:26,647 [DEBUG] Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-02-28 16:11:26,652 [INFO] Telnet Password: b8d913f992324dc2
2025-02-28 16:11:26,695 [INFO] Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2025-02-28 16:11:26,696 [INFO] Overridden settings:
{'BOT_NAME': 'kp',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'kp.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-02-28 16:11:26,842 [CRITICAL] Unhandled error in Deferred:
2025-02-28 16:11:26,843 [CRITICAL] Unhandled error in Deferred:
2025-02-28 16:11:26,850 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
2025-02-28 16:11:26,852 [CRITICAL] 
Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/.cache/pypoetry/virtualenvs/newsscraperproject-gIewBv5d-py3.12/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middlewares'
